%!TEX root = emnlp2016.tex

\section{Model Validation with Simulated Data}
\label{sec:valid}

Before using Capsule to explore a corpus of real messages (described
in \cref{sec:eval}), we provide a quantitative validation of the model
using simulated data.

We used the generative process in \cref{fig:generative-model} to
create ten data sets, each with 100 time intervals, ten general
topics, ten entities, and roughly 20,000 messages. We then used these
data sets to compare Capsule's event detection performance to that of
four baseline methods. We also compared the methods' abilities to
identify the most relevant messages for each event.

\subsection{Detecting Events}

For each data set, we ordered the time intervals from most to least
eventful, using the ``eventness'' measure described in
\cref{eq:eventness} and the simulated values of the latent
variables. We then treated these ranked lists of time intervals as
``ground truth'' and assessed how well each method was able to recover
them.

For Capsule itself, we used our approximate inference algorithm to
obtain a fitted variational distribution for each simulated data
set. We then ordered the time intervals using our ``eventness''
measure and the posterior expected values of the latent variables.

For our first baseline, we constructed an ``event-only'' version of
Capsule by dropping the first and second terms in
\cref{eq:poisrate}. We used this baseline to test whether modeling
``business as usual'' discussion makes it easier to detect significant
events. We obtained a fitted variational distribution for this model
using a variant of our approximate inference algorithm, and then
ordered the time intervals using our ``eventness'' measure, modified
appropriately, and the posterior expected values of the latent variables.

For our second baseline, we drew inspiration from previous work on
event detection in the context of news articles, and focused on each
time interval's deviation in term counts from the
average. Specifically, we ordered the time intervals $t=1, \ldots, T$
for each simulated data set according to this measure:
\begin{equation}
  m_t = \sum_{v=1}^V \sum_{\substack{d=1\\t_d \!=\! t}}^D \left\lvert n_{dv} - \frac{1}{D}\sum_{d=1}^D
  n_{dv} \right\rvert.
\label{eq:wordev}
\end{equation}

We added tf-idf term weights for our third baseline:
\begin{equation}
  m_t = \sum_{v=1}^V \textrm{tf-idf}\,(v) \sum_{\substack{d=1\\t_d\!=\!t}}^D \left\lvert n_{dv} - \frac{1}{D}\sum_{d=1}^D
  n_{dv} \right\rvert.
\label{eq:tfidfwordev}
\end{equation}

Finally, we randomly ordered the time intervals for each data set to
serve as a straw-man baseline.

We also experimented with baselines that involved term-count
deviations on the entity level and topic-usage deviations on the
document level~\cite{dou2012leadline}, but found that they were not
competitive.

For each data set, we compared each method's ranked list of time
intervals to the corresponding ``ground-truth'' list of time
intervals, by dividing the sum of the lists' actual set overlap at
each rank by the sum of their maximum set overlap at each rank:
\begin{equation}
\frac{\sum_{r=1}^T \vert S^{\textrm{truth}}_r \cap
  S^{\textrm{method}}_r \vert}{\sum_{r=1}^T r},
\label{eq:detection}
\end{equation}
where $S^{\textrm{truth}}_r$ is a set of the top $r$ time intervals
according to the ``ground-truth'' list and $S^{\textrm{method}}_r$ is
a set of the top $r$ time intervals according to the method.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{fig/sim_eventdetect.pdf}
\caption{Event detection performance using ten simulated data
  sets. Each dot represents the performance (\cref{eq:detection}) of
  a single method on a single data set; the shaded green area
  summarizes the distribution of performance for a single method.}
\label{fig:sim_eventdetect}
\end{figure}


\Cref{fig:sim_eventdetect} shows that Capsule outperforms all four
baseline methods. These results serve as a sanity check for the model
and its implementation.

%\footnote{The model was set with the same
%  number of topics $K=10$ and exponential decay $f$ used to simulate
%  the data.  More details on the decay function surround its formal
%  definition in \cref{eq:f}.}

\subsection{Identifying Relevant Messages}

For each data set, we created a list of the most relevant messages for
each time interval $t$ by computing $f(t_d, t)\,\epsilon_{dt}$ for
each message $d$ (using the simulated values of $\epsilon_{dt}$) and
ordering the messages accordingly. We then treated these ranked lists
of messages as ``ground truth'' and assessed how well Capsule and the
baseline methods were able to recover them.

For Capsule, we used our approximate inference algorithm to obtain a
fitted variational distribution for each simulated data set, and then,
for each time interval, ordered the messages according to $f(t_d,
t)\,\E[\epsilon_{dt}]$. For our second and third baselines, we ordered
the messages according per-document versions of \cref{eq:wordev} and
\cref{eq:tfidfwordev}---i.e.,
\begin{equation}
  m_{dt} = \sum_{v=1}^V \left\lvert n_{dv} - \frac{1}{D}\sum_{d=1}^D
  n_{dv} \right\rvert
\end{equation}
and
\begin{equation}
  m_{dt} = \sum_{v=1}^V \textrm{tf-idf}\,(v) \left\lvert n_{dv} - \frac{1}{D}\sum_{d=1}^D
  n_{dv} \right\rvert.
\end{equation}

For each data set, we compared each method's ranked list of documents
for each time interval to the corresponding ``ground-truth'' list, by
computing precision at 10 documents. The average precision for Capsule
was was 0.44, while the average precision for the ``event-only''
version of the model was 0.09. The other baselines recovered zero
relevant messages.

\section{Exploratory Analysis}
\label{sec:eval}

Capsule is intended to help analysts explore and understand their
data. In this section, we demonstrate its capabilities by analyzing a
corpus of over two million U.S. State Department cables from the
1970s.

\subsection{Data}

The National Archive collects diplomatic cables sent between the
U.S. State Department and its foreign embassies. We obtained a subset
of this corpus from the Central Foreign Policy Files at the National
Archives, via the History Lab at Columbia
University.\footnote{http://history-lab.org} The subset contains over
two million cables sent between 1973 and 1978. In addition to the text
of the cables, each message is labeled with its author (e.g., the
U.S. State Department, a particular embassy, or a named individual),
its recipients (often several), and the date the cable was sent. We
used a vocabulary of 6,293 terms and omitted cables with fewer than
three terms, resulting in 2,021,852 cables sent between 22,961
entities. We used weekly time intervals, as few cables were sent on
the weekends.

\subsection{Model Settings}

% what top-level shape/rate parameters did we use?

We ran our approximate inference algorithm for Capsule to obtain a
fitted variational distribution. We used $K=100$ general topics, the
exponential decay function in \cref{eq:f} with $\tau=4$, and top-level
hyperparameters $s=r=0.3$. With these settings, a single iteration of
the algorithm took about an hour.\footnote{Each iteration of our
  algorithm considers all messages. Modifying it to stochastically
  sample the data would reduce the time required to obtain an
  equivalent fitted variational distribution.}

\subsection{Quantitative Results}

Similar to the validation on simulated data discussed in \cref{sec:valid},
we can validate Capsule on this real-world data.  Here, we focus on event detection
and held-out data likelihood.

The History Lab at Columbia University provided us with a list of
thirty-nine real-world events during that took place between 1973 and
1978. These events are present in at least one of six reputable
collections of historic events, such as the Office of the Historian's
Milestones in the History of U.S. Foreign
Relations.\footnote{\url{https://history.state.gov/milestones/1969-1976}}

We ran Capsule and baseline comparison methods to recover these events, and used the nDCG metric to evaluate the methods.  The nDCG metric is discounted cumulative gain,
\begin{equation}
\mbox{DCG} = \sum_{j=1}^T \frac{\mathbf{1}[\mbox{interval at rank $j$ in known events}]}{\log j},
\end{equation}
divided by the ideal DCG value, or
\begin{equation}
\mbox{nDCG} = \frac{\mbox{DCG}}{\mbox{ideal DCG}}.
\end{equation}
As shown in \Cref{table:cables:ndcg}, Capsule outperforms the baselines.
\begin{table*}[bt]
\centering
\begin{tabular}{l c}
\toprule
\textbf{Method} & \textbf{nDCG} \\
\midrule
Capsule & 0.693 \\
Average tf-idf weighted word count deviation & 0.652 \\
Average unweighted word count deviation & 0.642 \\
Single term maximum tf-idf weighted deviation & 0.561 \\
Random (10k ave) & 0.557 \\
Single term maximum unweighted deviation & 0.555 \\
%Total tf-idf weighted word count deviation; \Cref{eq:tfidfwordev}\footnotemark & 0.543626 \\
%Total unweighted word count deviation; \Cref{eq:wordev} & 0.540892 \\
\bottomrule
\end{tabular}
\caption{Evaluation of Capsule and comparison baselines on a collection of 39 real-world events.  Capsule performs best.}
\label{table:cables:ndcg}
\end{table*}
%\footnotetext{Note that this metric performed best on simulated data.}

Additionally, we computed held-out validation data likelihood on the model and each of its component parts; \Cref{table:cables:ll} shows that the full Capsule model captures the data better than any of its component parts individually.
\begin{table}[bt]
\centering
\begin{tabular}{l c c}
\toprule
\textbf{Model} & \textbf{LL, 10 iter.} & \textbf{LL, final} \\
\midrule
Full Capsule & -1.62e7 & -1.52e7 \\
Entity Topics Only & -1.64e7 & -- \\
General Topics Only & -1.71e7 & -1.53e7 \\
Event Only & -1.79e7 & -- \\
\bottomrule
\end{tabular}
\caption{Log likelihood (LL) computed on validation data at 10 iterations and at convergence---the event only and entity only models are small enough that they converge with very few iterations. The full Capsule model achieves the lowest log likelihood in both cases.}
\label{table:cables:ll}
\end{table}

\subsection{Exploration}

Having validated that Capsule can detect real-world events, we now
turn to our primary goal---using Capsule to explore and understand a
corpus of messages.

\Cref{fig:cables_events} shows the ``eventness'' measure described in
\cref{sec:detecting} over time. High values---which are often
anomalous peaks---correspond to real-world events. One of the tallest
peaks occurs during the week of December 1, 1975, when the United
Nations General Assembly (UNGA) discussed omnibus decolonization. As
described in \cref{sec:detecting}, we can characterize this event by
computing $f(t_d, t)\,\E[\epsilon_{dt}]$ for each message $d$ and then
sorting the messages accordingly. \Cref{tab:decol} lists the
top-ranked cables.

\begin{table*}[tb]
\small
\centering
\begin{tabular}{cccl}
\toprule
$f(t_d, t) \E[\epsilon_{dt}]$ & \textbf{Date} & \textbf{Author Entity} & \textbf{Subject} \\
\midrule
4.60 & 1975-12-05 & Canberra & 30th UNGA: Item 23, Guam, Obmibus Decolonization and ... \\
4.26 & 1975-12-05 & Mexico & 30th UNGA-Item 23: Guam, Omnibus Decolonization and ... \\
4.21 & 1975-12-06 & State & 30th UNGA-Item 23: Guam, Omnibus Decolonization and ... \\
4.11 & 1975-12-03 & Dakar & 30th UNGA: Resolutions on American Samoa, Guam and ...\\
4.08 & 1975-12-04 & Monrovia & 30th UNGA: Item 23: Resolutions on decolonization and A...\\
\bottomrule
\end{tabular}
\caption{Top-ranked cables for the week of December 1, 1975, when the
  United Nations General Assembly discussed decolonization
  resolutions. Capsule accurately recovers cables related to this
  real-world event. Typos are intentionally copied from the data.}
\label{tab:decol}
\end{table*}

\begin{table*}[ht]
\small
\centering
\begin{tabular}{cccl}
\toprule
$f(t_d, t) \E[\epsilon_{dt}]$ & \textbf{Date} & \textbf{Author Entity} & \textbf{Subject} \\
\midrule
5.06 & 1975-05-15 & Sofia & Seizure of US merchant vessel by Cambodian forces \\
5.05 & 1975-05-15 & Dar es Salaam & Seizure of U.S.~merchant vessel by Cambodian forces \\
4.92 & 1975-05-16 & Lusaka & Seizure of US merchant vessel by Cambodian forces \\
4.61 & 1975-05-13 & Zagreb & Waiver request for INS Vienna visas Eagle name check... \\
4.59 & 1975-05-15 & State & eizure of US merchant Vessel by Cambodian forces \\
\bottomrule
\end{tabular}
\caption{Top-ranked cables for the week of May 12, 1975, when the
  S.S.~Mayaguez, an American merchant vessel, was captured. Capsule
  accurately recovers cables related to this real-world event. Typos
  are intentionally copied from the data.}
\label{tab:mayaguez}
\end{table*}

Another notable event was the seizure of the S.S.~Mayaguez, an
American merchant vessel, during May, 1975, at the end of the Vietnam
War. The top-ranked cables for this event are in
\cref{tab:mayaguez}. We can examine the individual cables to confirm
their relevancy and learn more about the event. For example, here is
the most relevant cable, according to Capsule:
\begin{shaded*} \tt{In absence of MFA Chief of Eighth Department Avramov, I
informed American desk officer Yankov of circumstances surrounding seizure
and recovery of merchant ship Mayaguez and its crew.  Yankov promised to
inform the Foreign Minister of US statement today  (May 15).
Batjer
}
\end{shaded*}


A third week of interest occurs in early July of 1976.  On July 4th, the US celebrated its Bicentennial, but on the same day, Israeli forces completed a hostage rescue mission---an Air France flight from Tel Aviv had been hijacked and taken to Entebbe, Uganda.  This event, like many events, is mostly discussed the week following the real-world event; relevant cables are shown in \Cref{sec:additional_results}, \Cref{tab:entebbe}.
The cable from Stockholm describing the ``Ugandan role in Air France hijacking'' begins with the following content, which reveals further information about the event.
\begin{shaded*} \tt{
1. We provided MFA Director of Political Affairs
Leifland with Evidence of Ugandan assistance to
hijackers contained in Ref A.  After reading material,{}
Leifland described it a ``quite good'', and said it{}
would be helpful for meeting MFA has scheduled for
early this morning to determine position GOS will take
at July 8 UNSC consideration of Israeli Rescue Operation. ...
}
\end{shaded*}
Capsule assumes that only one event occurs in each time interval---this example is a clear violation of this assumption, but it also demonstrates that the model successfully captures both events, even when they overlap.


In addition to events, Capsule can be used to explore the general themes of a corpus and entities' typical concerns.  Examples of general topics of conversation are shown in \Cref{sec:additional_results}, \Cref{tab:topics} and entity-exclusive topics are shown in \Cref{sec:additional_results}, \Cref{tab:entities}; these show us how entity topics absorb location-specific words, preventing these terms from overwhelming the general topics.

These exploratory results show that our model is successfully capturing when multiple entities are discussing the same subjects and that our model can be used to explore the underlying data by providing a structured scaffold from which to view the data.
















% \parhead{Data.}
% The National Archive collects communications between the U.S. Sate Department and its embassies.  We obtained a collection of these diplomatic messages from the History Lab at Columbia,\footnote{http://history-lab.org} which received them from the Central Foreign Policy Files at the National Archives.  The communications in this data set were sent between 1973 and 1978.

% In addition to the text of the cables themselves, each document is supplemented with information about who sent the cable (e.g., the State Department, the U.S. Embassy in Saigon, or an individual by name), who received the cable (often multiple entities), and the date the cable was sent.  We used a vocabulary of size 6,293 and omitted cables with fewer than three terms, resulting in a collection of 2,139,324 messages sent between 27,134 entities.  We selected a weekly duration for the time intervals, as few cables were sent on the weekends.

% \parhead{Model settings.}
% We fit Capsule with $K=100$ general topics and using an exponential decay $f$,
% \begin{equation}
% f(i_d, t) =
% \begin{cases}
%     0,			& \text{if } t > i_d\\
%     \exp\{-(i_d - t) / \tau\},          & \text{otherwise,}
% \end{cases}
% \label{eq:f}
% \end{equation}
% with mean lifetime $\tau=3$.  This mean lifetime indicates that most intervals would no longer be relevant after about three weeks.  With these settings on the cables data, fitting the model takes 2.8 hours per iteration;\footnote{Our algorithm is batch--we consider each data point for every iteration.  Modifying the algorithm to stochastically sample the data would reduce the time required to achieve an equivalent model fit.} results are shown on 15 iterations.

% \parhead{Results.}
% We begin our exploration by detecting events using Capsule.  With \Cref{eq:eventness} as our metric of ``eventness,'' we consider this metric over time, which is shown in \Cref{fig:cables_events}.  Here, peaks correspond to real-worlds events, several of which are labeled.\footnote{Appendix~\ref{sec:additional_results} contains an analogous figure on arXiv data, which shows that Capsule does not capture weekly events on data that does not contain real-world events at that resolution.}

% The tallest peak occurs the week of December 1, 1975, just prior to the Indonesian invasion of East Timor, which began December 7, 1975.  As discussed in \Cref{sec:model}, we sort documents by their event relevancy parameters $\epsilon$ to find cables that reflect an event.  \Cref{tab:timor} shows the top cables for the East Timor invasion.  Capsule accurately identifies this real-world event and recovers relevant cables.

% \begin{table*}[tb]
% \small
% \centering
% \begin{tabular}{cccl}
% \toprule
% $\epsilon$ & date & entity & subject \\
% \midrule
% 0.124   &  1975-12-03  &  State  & President's talking point on Portuguese Timor \\
% %0.121   &  1975-12-03  &  State  & President's talking point on Portuguese Timor \\
% 0.115   &  1975-12-04  &  State  & Timor we are repeating FYI a DAO message \\
% 0.112   &  1975-12-04  &  State  &  Legal problems relating to Portuguese Timor\\
% 0.105   &  1975-12-04  &  Secretary Peking & US Support for Timor resolution \\
% 0.102   &  1975-12-07  &  State  & Invasion of Portuguese Timor \\
% \bottomrule
% \end{tabular}
% \label{tab:timor}
% \caption{Top documents for the time interval of week December 1, 1975, just prior to the Indonesian invasion of East Timor, which began December 7, 1975; Capsule recovers relevant documents related to this real-world event.}
% \end{table*}

% \begin{table*}[htb]
% \small
% \centering
% \begin{tabular}{cccl}
% \toprule
% $\epsilon$ & date & entity & subject \\
% \midrule
% 0.090   &  1975-04-24  &  Mansfield, Mike & Assistance in evacuating family from South Vietnam \\
% 0.089   &  1975-04-24  &  Railsback, Tom & Assistance in evacuating friend from South Vietnam \\
% %0.088   &  1975-04-24  &  Mansfield, Mike  & Assistance in evacuating family from South Vietnam \\
% %0.086   &  1975-04-24  &  Williams, Harrison &  Assistance in evacuating family from South Vietnam \\
% 0.086   &  1975-04-24  &  Koch, Edward & Assistance in evacuating family from South Vietnam \\
% 0.086   &  1975-04-21  &  Schweiker, Richard & Support in evacuating family from Vietnam \\
% %$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
% 0.081   &  1975-04-25  &  Ketchum, William & Movement of South Vietnamese refugees to Guam \\
% 0.080   &  1975-04-21  &  Scott, Hugh & Whereabouts of missionaries in Vietnam \\
% \bottomrule
% \end{tabular}
% \label{tab:saigon}
% \caption{Top documents for the time interval of week April 21, 1975, just prior to the fall of Saigon on April 30, 1975; Capsule recovers relevant documents related to this real-world event.}
% \end{table*}

% The second tallest peak occurs the week of April 21, 1975, just prior to the fall of Saigon on April 30, 1975; \Cref{tab:saigon} shows the top cables for this event, which reflect the evacuation efforts that occurred during that week.  Unlike the East Timor event, where the most relevant communication exists at an administrative level, the evacuation of Saigon is best captured by individuals seeking help for family and friends.

% Another event peaks occurs the week of July 2, 1973; the top three words under event its description $\pi$ are \emph{bicentennial}, \emph{hijack}, and \emph{mercenary}.  Top cables under event relevancy $\epsilon$ surround the bicentennial celebration of United States (July 4, 1973) and the Air France hijacking incident that began on June 27; Israeli operatives rescued hostages from this incident on July 4th.

% Capsule also identifies events with smaller peaks, such as the death of Mao Tse-tung.  One of the top cables for this event is sent by Kissinger to all post with public affairs guidance: %the subject \emph{Death of Mao Tse Tung -- Public Affairs Guidance}:
% \begin{shaded*} \tt{1.  Missions should avoid all speculation about the
% possible effects of the death of Chairman Mao on
% US-PRC relationships as well as impact on internal
% Chinese developments.}

% \tt{2.  Official comments should be limited to the statements
% of top level administration officials, texts of which
% will follow by SEPTEL and wireless file.}
% \end{shaded*}
% \noindent In the other top cables for this event, embassies generally reported on press reactions and condolence or memorial ceremonies at their various locations.

% Capsule helps discovers events which follow a chain of related incidents, though connecting these events is left to the investigator.  For example, Capsule discovers an event the week the Sinai Interim Agreement was signed (September 4, 1975), but it also detects an event in mid-October 1975 about the hiring of observers and technicians for the Sinai peace keeping force.  Associated with this second event is a cable from London to the State department entitled \emph{FCO views on Syrian stance}:
% \begin{shaded*} \tt{Since conclusion of Sinai II negotiations, FCO
% officials have expressed considerable interest in prospects
% for next US effort to promote Syrian negotiations with Israelis. ...}
% %Basic FCO position remains one of pervasion admiration for success of
% %Secretary's tactics with Egyptians and Israelis tempered by recognition that
% %Syrian negotiating position will be a very tough nut to crack.
% %During recent ...}
% \end{shaded*}
% \noindent This cable and the sequence of events discovered by Capsule indicate that there is a longer lasting underlying situation.  Capsule cannot capture every aspect of these larger sequences of events, but it can provide insight into key moments so that investigators can explore both short-lived events and long-lasting political situations.

% \begin{table}
% \centering
% \small
% \begin{tabular}{c}
% \toprule
% top terms \\
% \midrule
% outlook, review, hire, personnel, invite, prepare \\
% arrest, incident, security, family, guard, death, jail \\
% locate, home, son, death, please, contact, father \\
% request, refugee, response, service, sale, asylum \\
% market, report, commercial, food, import, commerce \\
% fear, leadership, back, arm, role, threaten \\
% hotel, travel, reservation, visit, arrange, schedule \\
% \bottomrule
% \end{tabular}
% \label{tab:topics}
% \caption{Top vocabulary terms for a selection of general topics, one per row, according to topic distributions $\beta_k$.  Capsule identifies general diplomatic themes that can be relevant to any entity.}
% \end{table}

% \begin{table}
% \centering
% \small
% \begin{tabular}{cc}
% \toprule
% entity & top terms \\
% \midrule
% State & request, follow, embassy, meet, make \\
% Bangkok & bangkok, thailand, thai, refugee, follow \\
% Jerusalem & jerusalem, israeli, bank, report, say \\
% Stockholm & swedish, sweden, trade, meet, embassy \\
% %Casablanca & casablanca, morocco, moroccan, request, please, note \\
% Kampala & ugandan, nairobi, african, imperialist \\
% Ndjamean & chadian, chad, lagos, drought, austerity \\
% \bottomrule
% \end{tabular}
% \label{tab:entities}
% \caption{Top vocabulary terms for a selection of entities according to entity-exclusive topics $\eta_n$.  Capsule identifies entity-specific themes and interests. }
% \end{table}

% In addition to events, Capsule can be used to explore the general themes of a corpus and entities' typical concerns.  Examples of general topics of conversation are shown in \Cref{tab:topics} and entity-exclusive topics are shown in \Cref{tab:entities}; these show us how entity topics absorb location-specific words, preventing these terms from overwhelming the general topics.

% Appendix~\ref{sec:additional_results} contains additional examples of events discovered by Capsule, and more examples of general and entity-specific topics.

% These exploratory results show that our model is successfully capturing when multiple entities are discussing the same subjects and that our model can be used to explore the underlying data by providing a structured scaffold from which to view the data.

% \parhead{Simulations.}  We simulated data to provide a quantitative assessment of Capsule.
% We generated twenty data sets, each with 100 time steps, 10 general topics, and 100 entities. Each simulation contained about 55,000 documents and followed the generative process assumed by Capsule, as shown in \Cref{fig:generative-model}.

% \begin{figure}[t]
% \centering
% \includegraphics[width=\linewidth]{fig/sim_eventdetect.pdf}
% \caption{Event detection performance on twenty simulated datasets.  Capsule is able to detect events as well as comparison methods, but its performance has higher variance.}
% \label{fig:sim_eventdetect}
% \end{figure}

% To evaluate event detection, we created a ranked list of all time intervals and computed the overlap between a method and the simulated ground at every threshold; this generates an curve under which we can compute the area and normalized based on ideal performance---we refer to this metric as event detection AUC.

% %^ XXX citation

% The most successful of the baseline methods for event detection was average absolute error in word count relative to the mean, or
% \begin{equation}
% 	\sum_{v=1}^V\left[\sum_{d=1}^D \mbox{abs}\left( w_{d,v} - \frac{1}{\vert D \vert}\sum_{d=1}^D w_{d,v} \right) \right],
% \label{eq:wordev}
% \end{equation}
% and its tf-idf variant,
% \begin{equation}
% 	\sum_{v=1}^V\mbox{tf-idf}(v)\left[\sum_{d=1}^D \mbox{abs}\left( w_{d,v} - \frac{1}{\vert D \vert}\sum_{d=1}^D w_{d,v} \right) \right].
% \label{eq:tfidfwordev}
% \end{equation}
% \Cref{fig:sim_eventdetect} shows that Capsule can outperform these approaches for event detection, but that it has higher variance in performance.  We also consider an ``event only'' model---this is a model that only uses the interval-related subset of Capsule's parameters; comparing to this shows that is it important to model ``business as usual'' for improved event detection.  LDA based approaches like average deviation from mean in topic space~\cite{dou2012leadline} do not perform well for event detection as deviations in topic space are too coarse to provide a meaningful signal.

% \begin{figure}[h]
% \centering
% \includegraphics[width=\linewidth]{fig/precision10.pdf}
% \caption{Precision of recovering the top ten most relevant documents, averaged over all time intervals.  Capsule performs best, averaged over twenty simulations.}
% \label{fig:sim_precision}
% \end{figure}

% Once events have been identified, our next task is to identify relevant documents; to evaluate this, we calculate precision of recovering the top ten documents.  LDA is useful in finding relevant documents by selecting documents that deviate from the mean in topic space.  Word count deviations for each document (similar to Equations~\ref{eq:wordev} and~\ref{eq:tfidfwordev}) perform close to random for document recovery.

% Finding documents based on absolute deviation from the mean works better in LDA topic space, but /home/statler/achaney/cables/src/event_detect/scripts/sweep5linearv2/fitnot over the full vocabulary.  Word count deviations, which performed well for event detection, performed worse than random for document recovery.  Both Capsule and its event-only partial model outperform all comparison methods in terms of document recovery.  \Cref{fig:sim_precision} shows precision of recovering the top ten documents.

% We assessed the sensitivity of our model to three different decay functions $f$: exponential, linear, and step functions.  We simulated data for each function and then fit Capsule using every permutation of $f$ and multiple settings for event decay duration.  In all cases, we found that the model is not sensitive to decay shape or duration; details are in Appendix~\ref{sec:additional_results}.

% \parhead{Comparisons on cables.}
% We ran the word count based approaches on the cables data and found that they were difficult to interpret and did not recover important historical events.  For instance, none detected the evacuation of Saigon, a major historical event in the corpus.  The LDA-based approaches do not yield large gains in run time over Capsule and do not provide the granularity needed to capture substantial events.
